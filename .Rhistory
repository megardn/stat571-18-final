load("data/covid_cases_vaccines_clean.Rda")
#skim(covid)
#some discrepancy in how countries are named, gonna fix that
wsd.country <- levels(wsd$country)
covid.country <- levels(covid$country)
#setdiff(wsd.country, covid.country) #only in wsd, not covid
#setdiff(covid.country, wsd.country) #only in covid, not wsd
covid$country <- recode_factor(covid$country, "UK"="United Kingdom", "Gambia"="Gambia, The", "Laos"="Lao PDR", "Egypt"="Egypt, Arab Rep.", "South Korea"="Korea, Rep.", "USA"="United States", "Russia"="Russian Federation", "Venezuela"="Venezuela, RB", "Democratic Republic Of The Congo"="DRC")
wsd$country <- recode_factor(wsd$country,  "Iran, Islamic Rep."="Iran", "Bosnia and Herzegovina"="Bosnia And Herzegovina", "Cote d'Ivoire"="Cote D Ivoire", "Guinea-Bissau"="Guinea Bissau", "Kyrgyz Republic"="Kyrgyzstan", "North Macedonia"="Macedonia", "Eswatini"="Swaziland", "Vietnam"="Viet Nam", "Timor-Leste"="Timor Leste", "Slovak Republic"="Slovakia", "Congo, Rep."="Congo", "Congo, Dem. Rep."="DRC")
# latest data for each country, restricted to 2016 or later
wsd.latest <- wsd %>% arrange(Year) %>%
group_by(country) %>%
filter(Year >= 2016) %>%
slice_tail(n=1) %>%
ungroup()
colnames(wsd.latest)[5:31] <- paste(colnames(wsd.latest)[5:31], "latest", sep = "_") #add suffix
table(as.factor(wsd.latest$Year_latest)) # see yr frequencies
# averages for numeric
wsd.avg.num <- wsd %>% arrange(Year) %>%
group_by(country) %>%
summarise_if(is.numeric, mean) %>%
ungroup() %>%
dplyr::select(-Year)
colnames(wsd.avg.num)[2:25] <- paste(colnames(wsd.avg.num)[2:25], "avg", sep = "_") #add suffix
# create a function to find the mode. Taken from: https://stackoverflow.com/questions/2547402/how-to-find-the-statistical-mode
Mode <- function(x) {
ux <- unique(x)
ux[which.max(tabulate(match(x, ux)))]
}
# mode for factors
wsd.avg.fac <- wsd %>% arrange(Year) %>%
group_by(country) %>%
mutate(WorldBankIncomeClass = Mode(WorldBankIncomeClass),
RegimeType = Mode(RegimeType),
nYears=n()) %>% #count how many years are being averaged for each country
ungroup() %>%
dplyr::select(country, WorldBankIncomeClass, RegimeType, nYears) %>%
distinct()
colnames(wsd.avg.fac)[2:4] <- paste(colnames(wsd.avg.fac)[2:4], "avg", sep = "_") #add suffix
# #make sure modes returned as expected
# angola <- wsd$WorldBankIncomeClass[wsd$country=="Angola"]
# Mode(angola)
# wsd.avg.fac$WorldBankIncomeClass[wsd.avg.fac$country=="Angola"]
# #looks good!
wsd.avg <- merge(wsd.avg.fac, wsd.avg.num, by="country") #rejoin num and fac
table(as.factor(wsd.avg$nYears_avg)) # see yr frequencies
# one predictor dataframe to rule them all
wsd.df_list <- list(wsd.latest, wsd.avg) #dfs to merge, ordered purposefully for removing correlated predictors
wsd.sum.wide <- wsd.df_list %>% reduce(full_join, by='country')
head(wsd.sum.wide)
#removing 1 of each very colinear pair, method from https://statisticsglobe.com/remove-highly-correlated-variables-from-data-frame-r
#stash year and non-numeric variables
wsd.fac <- wsd.sum.wide %>%
select(negate(is.numeric)| "Year_latest", "nYears_avg")
#plot
# create correlation plot to see whether some variables are highly correlated (not tolerated by lm)
wsd.sum.wide %>%
select_if(., is.numeric) %>%
cor(., use = "pairwise.complete.obs") %>%
corrplot(method = "color",
type = "upper", order = "hclust",
addCoef.col = "black", # Add coefficient of correlation
tl.col="black", tl.srt = 45, #Text label color and rotation
# hide correlation coefficient on the principal diagonal
diag = FALSE
)
#get colinearities
wsd.num <- wsd.sum.wide %>%
select(-c("Year_latest", "nYears_avg")) %>%
select_if(., is.numeric)
wsd.corr <- wsd.num %>%
cor(., use="pairwise.complete.obs")
#removing upper triangle
wsd.corr[upper.tri(wsd.corr)] <- 0
diag(wsd.corr) <- 0
#remove vars at abs(0.97) threshold - keeping high to preserve as many variables as possible (also b/c we expect things to be correlated IRL)
wsd.list <-  apply(wsd.corr, 2, function(x) any(abs(x) > 0.97)) #list highly correlated variables
wsd.nocor <- wsd.num[ , !wsd.list]
#add back factors
wsd.nocor <- cbind(wsd.fac, wsd.nocor)
dim(wsd.nocor)
head(wsd.nocor)
#last day with data for each country
last.timepoint1 <- covid %>% group_by(country) %>%
arrange(country,date) %>%
slice_tail(n=1) %>%
ungroup()
last.timepoint_filt <- last.timepoint1[, which(colMeans(!is.na(last.timepoint1)) > 0.5)] #remove cols with NA > 50%
#skim(last.timepoint_filt)
# get missing column names
missing_vac_cols <-  names(which(colMeans(is.na(last.timepoint1)) > 0.5))
# add last reported (within 2022) vaccination info
vac_info_2022 <- covid %>%
drop_na(people_vaccinated_per_hundred) %>%   # filter to keep only non-NA in people_vaccinated_per_hundred
group_by(country) %>%
filter(date == max(date)) %>%   # keep last reported date for every country
filter(year == 2022) %>% # keep only countries who last reported in 2022 (as we are interested in a recent vaccination status)
# filter(month_year == "2022-03-01") # could also filter for march 2022 specifically
dplyr::select(country, date, missing_vac_cols) %>% # keep only variables not yet included in last.timepoint
rename(date.vac = date)# rename the date to correspond to last reported vaccine info
# merge the last reported vaccination info with last reported cases/deaths info
last.timepoint <- merge(last.timepoint_filt, vac_info_2022, by = "country")
colnames(last.timepoint)[2:43] <- paste(colnames(last.timepoint)[2:43], "last", sep = "_") #add suffix
#names(last.timepoint)
# #find date of vaccination events
# table(covid$vaccination_events)
# table(covid$vaccine_dose_events)
summary(last.timepoint$date.vac_last)
# find the date each country reported starting to vaccinate
vac_start_df <- covid %>%
dplyr::select(country, date, vaccination_events) %>%
filter(vaccination_events == "vac_start") %>%
mutate(days.to.start_rel = as.numeric(difftime(date, min(date), units = "days")),
days.to.start_abs = as.numeric(difftime(date, "2020-12-01", units = "days"))) %>%
rename(date.first.vac = date)
# adding date of first vaccination for each country back to the covid df so it can be used as a cutoff
vac_start_date <- vac_start_df %>% dplyr::select(country, date.first.vac)
covid <- full_join(covid, vac_start_date, by ="country")
# cases & deaths up until vaccines start - USE THIS!
covid_prevac <- covid %>%
group_by(country) %>%
drop_na(date.first.vac) %>%
subset(date < date.first.vac) %>%
arrange(country,date) %>%
slice_tail(n=1) %>%
ungroup() %>%
dplyr::select("country"| contains("case") | contains("death"))
colnames(covid_prevac)[2:19] <- paste(colnames(covid_prevac)[2:19], "prevac", sep = "_") #add suffix
#peak rates up until vaccinations start - USE THIS
covid_maxrate <- covid %>%
drop_na(date.first.vac) %>%
subset(date < date.first.vac) %>%
dplyr::select("country" | contains(c("new", "daily"))) %>%
dplyr::select(-contains("vac")) %>% #drop vac cols
group_by(country) %>%
mutate_if(is.numeric, ~replace(., is.na(.), -1)) %>% #temporarily replace na's with -1
summarise_if(is.numeric, max) %>%
na_if(-1) %>% #set -1's back to na
rename(daily.new.cases.per.100 = daily_new_cases_per_hundred,
daily.new.deaths.per.100 = daily_new_deaths_per_hundred,
monthly.new.cases.per.100 = monthly_new_cases_per_hundred,
monthly.new.deaths.per.100 = monthly_new_deaths_per_hundred,
weekly.new.cases.per.100 = weekly_new_cases_per_hundred,
weekly.new.deaths.per.100 = weekly_new_deaths_per_hundred) #using . and _ separators to match WSD in case we want to pivot long later
colnames(covid_maxrate)[2:13] <- paste(colnames(covid_maxrate)[2:13], "max", sep = "_") #add suffix
#df for cases and deaths
case.df_list <- list(covid_maxrate, covid_prevac) #ordered to prioritize when removing correlated vars
covid.predict <- case.df_list %>% reduce(full_join, by='country') %>% as.data.frame() #join
#skim(covid.predict)
#removing 1 of each very colinear pair, method from https://statisticsglobe.com/remove-highly-correlated-variables-from-data-frame-r
#stash year and non-numeric variables (just country)
covid.fac <- covid.predict %>%
select(negate(is.numeric))
#plot
# create correlation plot to see whether some variables are highly correlated (not tolerated by lm)
covid.predict %>%
select_if(., is.numeric) %>%
cor(., use = "pairwise.complete.obs") %>%
corrplot(method = "color",
type = "upper", order = "hclust",
addCoef.col = "black", # Add coefficient of correlation
tl.col="black", tl.srt = 45, #Text label color and rotation
# hide correlation coefficient on the principal diagonal
diag = FALSE
)
#get colinearities
covid.num <- covid.predict %>%
select(-contains("Year")) %>%
select_if(., is.numeric)
covid.corr <- covid.num %>%
cor(., use="pairwise.complete.obs")
#removing upper triangle
covid.corr[upper.tri(covid.corr)] <- 0
diag(covid.corr) <- 0
#remove vars at abs(0.97) threshold - keeping high to preserve as many variables as possible (also b/c we expect things to be correlated IRL)
covid.list <-  apply(covid.corr, 2, function(x) any(abs(x) > 0.97)) #list highly correlated variables
covid.nocor <- covid.num[ , !covid.list]
#add back factors
covid.nocor <- cbind(covid.fac, covid.nocor)
dim(covid.nocor)
head(covid.nocor)
#days until country admins 1 dose per person
vac_1_dose <- covid %>%
dplyr::select(country, date, vaccine_dose_events, date.first.vac) %>% #
filter(vaccine_dose_events == "1_dose")%>%
mutate(days.to.1d_rel = as.numeric(difftime(date, min(date), units = "days")),
days.to.1d_abs = as.numeric(difftime(date, "2020-12-01", units = "days")), # setting Dec 1, 2020 as vaccine baseline to compare across vaccine events
days.to.1d_fromstart = as.numeric(difftime(date, date.first.vac, units = "days"))
)
#vac_1_dose[which.min(vac_1_dose$date),] #first country to get one dose per person
#days until country admins 2 doses per person
vac_2_doses <- covid %>%
dplyr::select(country, date, vaccine_dose_events, date.first.vac) %>%
filter(vaccine_dose_events == "2_doses")%>%
mutate(days.to.2d_rel = as.numeric(difftime(date, min(date), units = "days")),
days.to.2d_abs = as.numeric(difftime(date, "2020-12-01", units = "days")),
days.to.2d_fromstart = as.numeric(difftime(date, date.first.vac, units = "days"))
)
#vac_2_doses[which.min(vac_2_doses$date),] #first country to hit 2 doses
#days until country reports vaccinating 10% of pop
vac_10_df <- covid %>%
dplyr::select(country, date, vaccination_events, date.first.vac) %>%
filter(vaccination_events == "vac_10pct") %>%
mutate(days.to.10pct_rel = as.numeric(difftime(date, min(date), units = "days")),
days.to.10pct_abs = as.numeric(difftime(date, "2020-12-01", units = "days")),
days.to.10pct_fromstart = as.numeric(difftime(date, date.first.vac, units = "days"))
)
#nrow(vac_10_df)
#days until country reports vaccinating 20% of pop
vac_20_df <- covid %>%
dplyr::select(country, date, vaccination_events, date.first.vac) %>%
filter(vaccination_events == "vac_20pct") %>%
mutate(days.to.20pct_rel = as.numeric(difftime(date, min(date), units = "days")),
days.to.20pct_abs = as.numeric(difftime(date, "2020-12-01", units = "days")),
days.to.20pct_fromstart = as.numeric(difftime(date, date.first.vac, units = "days"))
)
#nrow(vac_20_df)
#days until country reports vaccinating 30% of pop
vac_30_df <- covid %>%
dplyr::select(country, date, vaccination_events, date.first.vac) %>%
filter(vaccination_events == "vac_30pct") %>%
mutate(days.to.30pct_rel = as.numeric(difftime(date, min(date), units = "days")),
days.to.30pct_abs = as.numeric(difftime(date, "2020-12-01", units = "days")),
days.to.30pct_fromstart = as.numeric(difftime(date, date.first.vac, units = "days"))
)
#nrow(vac_30_df)
#days until country reports vaccinating 50% of pop
vac_50_df <- covid %>%
dplyr::select(country, date, vaccination_events, date.first.vac) %>%
filter(vaccination_events == "vac_50pct") %>%
mutate(days.to.50pct_rel = as.numeric(difftime(date, min(date), units = "days")),
days.to.50pct_abs = as.numeric(difftime(date, "2020-12-01", units = "days")),
days.to.50pct_fromstart = as.numeric(difftime(date, date.first.vac, units = "days"))
)
# mean daily rate of vaccinations per million ppl in first 6 months of each country's administration
vac_rate <- covid %>%
dplyr::select(country, date, daily_vaccinations_per_million, date.first.vac) %>%
filter(daily_vaccinations_per_million > 0,
date <= (date.first.vac %m+% months(6))) %>% # daily vaccinations in 1st 6 mo - make relative to their own vaccine start date
drop_na(daily_vaccinations_per_million) %>%
group_by(country) %>%
summarise(daily.vac.per.mil_6moavg = mean(daily_vaccinations_per_million))
# max rate of vaccinations administration
vac_maxrate <- covid %>%
dplyr::select(country, date, daily_vaccinations_per_million, daily_vaccinations_raw, daily_vaccinations) %>%
group_by(country) %>%
mutate_if(is.numeric, ~replace(., is.na(.), -1)) %>% #temporarily replace na's with -1
summarise_if(is.numeric, max) %>%
na_if(-1) %>% #set -1's back to na
rename(daily.vac.raw_max = daily_vaccinations_raw,
daily.vac_max = daily_vaccinations,
daily.vac.per.mil_max = daily_vaccinations_per_million)
#big df for vaccine info
last.vac <- last.timepoint %>% dplyr::select("country"| contains("vacc"))#get just vaccine stuff from  last.timepoint
vac.df_list <- list(vac_1_dose, vac_2_doses, vac_start_df, vac_10_df, vac_20_df, vac_30_df, vac_50_df, vac_rate, vac_maxrate, last.vac)
#drop date and event info since this is contained in col names
for (i in 1:length(vac.df_list)) {
vac.df_list[[i]] <- vac.df_list[[i]] %>% dplyr::select(-c(contains("date") | contains("events")))
}
vac.dump <- vac.df_list %>% reduce(full_join, by='country') %>% as.data.frame() #join
#skim(vac.dump)
vac.sum <- vac.dump %>% dplyr::select(
country,
days.to.start_rel, #days until a country reports starting to administer vaccines, with the 1st country to start vaccinating as a baseline
days.to.10pct_fromstart, #days between starting vaccinations and administering to 10% of pop
daily.vac.per.mil_6moavg, #mean daily vaccinations in the first 6 months of administering
people_vaccinated_per_hundred_last, #number of ppl vaccinated (at least once) at last report (sometime in 2022)
daily.vac.per.mil_max, #max number of vaccinations reported in a single day
total_vaccinations_per_hundred_last,# number of vaccine doses per hundred ppl at last report (sometime in 2022)
people_fully_vaccinated_per_hundred_last # number of people that received the full vaccine (typically 2 doses)
)
skim(vac.sum)
#drop NAs before PCA
vac.sum.pca <- vac.sum %>% na.omit()
nrow(vac.sum.pca)
vax.pca3 <- prcomp(x = vac.sum.pca[,-1], scale. = TRUE, center = TRUE)
vax.pca3$rotation
summary(vax.pca3) # PVE of PC1=73.3%
plot(summary(vax.pca3)$importance[2, ],  # PVE
ylab="PVE",
xlab="Number of PC's",
pch = 16,
main="Scree Plot of PVE for Vaccination variables")
# Following the elbow rule, the first PC1 clearly explains a sufficient amount of variance. We will thus keep the first PC.
vac.sum.with.VSI <- vac.sum.pca # copy the data
vac.sum.with.VSI$VSI <- -vax.pca3$x[,1] # append the VSI (inverse signed PC1 scores), where a positive nb means a country was good at getting people vaccinated
# numerical summary
skim(vac.sum.with.VSI)
# plot sorted VSI scores
vac.sum.with.VSI %>%
ggplot(aes(x = reorder(country, VSI),
y = VSI, fill = country)) +
geom_bar(show.legend = FALSE, stat = "identity") +
xlab("Country") +
ylab("VSI") +
ggtitle("Vaccination Success Index score") +
theme_bw() +
theme(axis.text.x = element_text(angle = 60, hjust=1))
ggplot(vac.sum.with.VSI, aes(x = reorder(country, -VSI), y = VSI, fill = country)) +
geom_bar(stat = "identity")
#summary(vac.sum.with.VSI$VSI)#VSI range
#merging WSD predictors with cases, deaths & maxrate data
case.wsd.wide <- inner_join(wsd.nocor, covid.nocor, by="country") #predictors only
#skim(case.wsd.wide)
#adding in VSI
yval <- vac.sum.with.VSI %>% dplyr::select("country", "VSI")
final.df <- inner_join(case.wsd.wide, yval,  by=("country"))
#names(final.df)
n_unique(final.df$country)
##WRITE CSVs FOR MODELING##
#write.csv(case.wsd.wide, "data/case.wsd.wide-predictors.csv", row.names = FALSE)
#write.csv(final.df, "data/final.df.csv", row.names = FALSE)
# Split the data
N <- length(final.df$country)
n1 <- floor(.85*N)
n2 <- floor(.15*N)
#dropping vars we don't want to predict on
df.pred <- final.df %>% dplyr::select(-c(country, Continent, Country.Code, Year_latest, nYears_avg)) #drop years!
set.seed(10)
# Split data to three portions of .6, .2 and .2 of data size N
idx_train <- sample(N, n1)
idx_val <- (which(! seq(1:N) %in% idx_train))
data.train <- as.data.frame(df.pred[idx_train,])
data.val <- as.data.frame(df.pred[idx_val,])
# economic factors lm
lm.econ.1 <- lm(data = data.train, formula = VSI ~ ExportGoodsServices.GDP_avg +
FinalConsumptionExpenditure.GDP_avg +
GDP.Current_avg +
GDP.PerCapita.Current_avg +
ConsumerPriceInflation_avg)
summary(lm.econ.1)
#Anova(lm.econ.1)
#commented b/c fit using the 60% data.train, will need to be checked:
# # remove non-significant variables w backward selection
# lm.econ.1.refined <- update(lm.econ.1, .~. -FinalConsumptionExpenditure.GDP_avg)
# #Anova(lm.econ.1.refined)
# lm.econ.2.refined <- update(lm.econ.1.refined, .~. -ExportGoodsServices.GDP_avg)
# #Anova(lm.econ.2.refined)
# lm.econ.3.refined <- update(lm.econ.2.refined, .~. -GDP.Current_avg )
# #Anova(lm.econ.3.refined)
# lm.econ.4.refined <- update(lm.econ.3.refined, .~. -ConsumerPriceInflation_avg)
# Anova(lm.econ.4.refined)
# build covid model
lm.covid.1 <- lm(VSI ~ cumulative_total_cases_per_hundred_prevac +
cumulative_total_deaths_per_hundred_prevac +
monthly.new.cases.per.100_max +
monthly.new.deaths.per.100_max +
monthly_new_cases_per_hundred_prevac, data = data.train)
summary(lm.covid.1)
Anova(lm.covid.1)
#LOL only the intercept is significant, going to do some forward selection - start with cumulative_total_cases_per_hundred_prevac!
lm.covid.death <- lm(VSI ~ cumulative_total_deaths_per_hundred_prevac, data = data.train)
summary(lm.covid.death)
lm.covid.f2 <- update(lm.covid.death, .~. + cumulative_total_cases_per_hundred_prevac)
summary(lm.covid.f2) #tried a few different options, adding more COVID vars don't seem to be predictive
Anova(lm.covid.f2)
# based on Anova, looks like cumulative_total_cases_per_hundred_prevac is the way to go - forward selection on this!
lm.covid.case <- lm(VSI ~ cumulative_total_cases_per_hundred_prevac, data = data.train)
summary(lm.covid.case)
# build political & country development index model
lm.political.1 <- lm(VSI ~ WorldRegion +
Electricity.Access_avg +
GDP.PerCapita.Current_avg +
UrbanPopulation.Prop_avg +
LifeExpenctancy_avg +
CompulsoryEducationDurationYears_latest +
WomenInBusinessLawIndex_avg +
WorldBankIncomeClass_avg +
RegimeType_avg +
IndividualsUsingInternet_latest,
data = data.train)
summary(lm.political.1)
Anova(lm.political.1)
#commented b/c fit using the 60% data.train, will need to be checked:
# # remove non-significant variables w backward selection
# lm.political.1.refined <- update(lm.political.1, .~. -GDP.PerCapita.Current_avg)
# #Anova(lm.political.1.refined)
# lm.political.2.refined <- update(lm.political.1.refined, .~. -WorldBankIncomeClass_avg)
# #Anova(lm.political.2.refined)
# lm.political.3.refined <- update(lm.political.2.refined, .~. -UrbanPopulation.Prop_avg)
# #Anova(lm.political.3.refined)
# lm.political.4.refined <- update(lm.political.3.refined, .~. -Electricity.Access_avg)
# #Anova(lm.political.4.refined)
# lm.political.5.refined <- update(lm.political.4.refined, .~. -IndividualsUsingInternet_latest)
# #Anova(lm.political.5.refined)
# lm.political.6.refined <- update(lm.political.5.refined, .~. -CompulsoryEducationDurationYears_latest)
# Anova(lm.political.6.refined)
# fit using the 60% data.train, will need to be checked:
# build full model
lm.full <- lm(VSI ~ GDP.PerCapita.Current_avg +
cumulative_total_cases_per_hundred_prevac +
WorldRegion +
LifeExpenctancy_avg +
WomenInBusinessLawIndex_avg +
RegimeType_avg,
data = data.train)
Anova(lm.full)
summary(lm.full)
# remove non-significant variables
lm.full.1.refined <- update(lm.full, .~. -cumulative_total_cases_per_hundred_prevac)
Anova(lm.full.1.refined)
lm.full.2.refined <- update(lm.full.1.refined, .~. -GDP.PerCapita.Current_avg)
Anova(lm.full.2.refined)
summary(lm.full.2.refined)
# plotting model diagnosis plots
plot(lm.full.2.refined, 1:2)
# get life expectancy p value
lm.full.2.refined.summ <- summary(lm.full.2.refined)
pval <- lm.full.2.refined.summ$coefficients[["LifeExpenctancy_avg", "Pr(>|t|)"]]
# get life expectancy correlation with VSI
cor_value <- cor(data.train$LifeExpenctancy_avg, data.train$VSI, use = "complete.obs")
plot_VSI_lifexp <- final.df %>% # using full df here to include country information
ggplot(aes(x = LifeExpenctancy_avg, y = VSI)) +
geom_point(aes(group = country, color = country), show.legend = FALSE) +
geom_smooth(method = "lm", color = "grey") +
theme_bw() +
ggtitle("Association between life expectancy and VSI") +
xlab("Life expectancy (average)") +
annotate("text", x = 56, y = max(final.df["VSI"]) - 0.5, # position
size = 4, # font size
label = paste0("Correlation: ", sprintf("%.3f", cor_value), "\n", # correlation label
"p-value = ", sprintf("%.3f", pval))) # pvalue label
plot_VSI_lifexp
# ggplotly(plot_VSI_lifexp) # generate interactive plot
# remove all rows containing NAs (LASSO does not work without this step) - lost 9 rows :(
data.train.sub <- na.omit(data.train)
nrow(data.train.sub)
# create matrices to feed into gmnet
Y <- as.matrix(data.train.sub[, 61]) # extract Y (VSI)
X <- model.matrix(VSI~., data = data.train.sub)[, -61] # remove the first (interecept) column with only 1s
# to control the randomness in K folds
set.seed(10)
# run LASSO
lasso.avg <- cv.glmnet(X, Y, alpha = 1, nfolds = 10, intercept = TRUE)
# plot LASSO results
plot(lasso.avg)
lasso.avg$lambda.1se # use lambda.1se to select the smaller model
coef.1se <- coef(lasso.avg, s = "lambda.1se") # get coefficients
coef.1se <- coef.1se[which(coef.1se != 0),] # show variables with non-zero coefficients
# output variable names
coef.1se <- rownames(as.matrix(coef.1se))[-1]
coef.1se
# output lm based on LASSO
coef.1se <- coef(lasso.avg, s="lambda.1se")  #s=c("lambda.1se","lambda.min") or lambda value
coef.1se <- coef.1se[which(coef.1se != 0),]   # get the non=zero coefficients
var.1se <- rownames(as.matrix(coef.1se))[-1] # output the variable names without intercept
wsd.avg.vsi.lasso <-  data.train.sub %>%
select(c("VSI", var.1se)) # get a subset with response and LASSO output
# run relaxed LASSO
fit.1se.lm <- lm(VSI~., data = wsd.avg.vsi.lasso)
summary(fit.1se.lm)
single.tree1 <- tree(VSI ~ ., data.train.sub, control=tree.control(nobs=nrow(data.train.sub),
minsize=4,
mindev=0.009))
plot(single.tree1)
text(single.tree1, pretty = 1)
title("Single Tree | VSI Prediction")
# no more data.test - can split data.train before running single tree if you want
#tree.test.prediction <- predict(single.tree1, newdata = data.test)
#tree.mse <- mean((data.test$VSI - tree.test.prediction)^2) # calculate mean squared prediction error
#tree.mse
set.seed(1) # for reproducibility, we set the seed
fit.1.rf <- randomForest(VSI~., data.train.sub, mtry=6, ntree=500)
plot(fit.1.rf$mse, xlab="Number of Trees", col="red", ylab="OOB MSE")
title(main = "OOB Test Error by Number of Trees Used")
set.seed(10)
max.mtry <- ncol(data.train.sub)
error.p <- 1:max.mtry
for (p in 1:max.mtry)
{
rf.temp <- randomForest(VSI~., data.train.sub, mtry=p, ntree=100)
error.p[p] <- rf.temp$mse[100]
}
plot(1:max.mtry, error.p,
main = "Testing Errors of mtry with 100 trees",
xlab="mtry",
ylab="OOB MSE")
lines(1:max.mtry, error.p)
set.seed(2)
fit.final.rf <- randomForest(VSI~., data.train.sub, mtry=20, ntree=100)
plot(fit.final.rf)
set.seed(2)
fit.final.rf <- randomForest(VSI~., data.train.sub, mtry=30, ntree=100)
plot(fit.final.rf)
set.seed(2)
fit.final.rf <- randomForest(VSI~., data.train.sub, mtry=34, ntree=100)
plot(fit.final.rf)
set.seed(2)
fit.final.rf <- randomForest(VSI~., data.train.sub, mtry=30, ntree=100)
plot(fit.final.rf)
set.seed(2)
fit.final.rf <- randomForest(VSI~., data.train.sub, mtry=35, ntree=100)
plot(fit.final.rf)
set.seed(2)
fit.final.rf <- randomForest(VSI~., data.train.sub, mtry=30, ntree=100)
plot(fit.final.rf)
set.seed(2)
fit.final.rf <- randomForest(VSI~., data.train.sub, mtry=30, ntree=100)
plot(fit.final.rf)
fit.final.rf$mse[100]
single.tree1 <- tree(VSI ~ ., data.train.sub, control=tree.control(nobs=nrow(data.train.sub),
minsize=4,
mindev=0.009))
plot(single.tree1)
text(single.tree1, pretty = 1)
title("Single Tree | VSI Prediction")
single.tree1 <- tree(VSI ~ ., data.train.sub, control=tree.control(nobs=nrow(data.train.sub),
minsize=4,
mindev=0.009))
plot(single.tree1)
text(single.tree1, pretty = 1)
title("Single Tree | VSI Prediction")
